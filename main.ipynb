{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 08:04:40.907093: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-01 08:04:40.950566: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 08:04:41.611088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ec22150/MSCPRJ/MSC-PRJ/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from data.datasets import AMIGOS, series_collate\n",
    "from architecture.MainNetwork import MainNetwork\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "loader_kwargs = {'num_workers': 4, 'pin_memory': True, 'shuffle': True, 'drop_last': True}\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "savemodel = 'models/'\n",
    "if not os.path.exists(savemodel):\n",
    "    os.makedirs(savemodel)\n",
    "root_path = 'data/face_segments'\n",
    "labels_path = 'data/Data_Preprocessed_segmented.json'\n",
    "vids_dir = 'data/vids_segments'\n",
    "num_class = 4096\n",
    "batch_size = 6\n",
    "learning_rate = 0.00001\n",
    "epochs = 20\n",
    "alpha = 2\n",
    "beta = 1\n",
    "gamma = 1\n",
    "downsample = 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'log'\n",
    "log_writer = SummaryWriter(os.path.join(*[log_dir, 'AMIGOS', 'Train', datetime.now().strftime('%b%d_%H-%M-%S')]))\n",
    "\n",
    "x_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize([0.4168, 0.3074, 0.2607], [0.2426, 0.1997, 0.1870])\n",
    "])\n",
    "\n",
    "y_transform = transforms.Compose([\n",
    "    torch.FloatTensor\n",
    "])\n",
    "\n",
    "train_dataset = AMIGOS(\n",
    "    root_path=root_path,\n",
    "    labels_path=labels_path,\n",
    "    vids_dir=vids_dir,\n",
    "    x_transform=x_transform,\n",
    "    y_transform=y_transform,\n",
    "    downsample=downsample\n",
    ")\n",
    "\n",
    "x_transform = transforms.Compose([\n",
    "    transforms.Normalize([0.4168, 0.3074, 0.2607], [0.2426, 0.1997, 0.1870])\n",
    "])\n",
    "\n",
    "val_dataset = AMIGOS(\n",
    "    root_path=root_path,\n",
    "    labels_path=labels_path,\n",
    "    vids_dir=vids_dir,\n",
    "    x_transform=x_transform,\n",
    "    y_transform=y_transform,\n",
    "    downsample=downsample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training UID 37 with 1110 samples\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# training\u001b[39;00m\n\u001b[1;32m     26\u001b[0m model \u001b[39m=\u001b[39m MainNetwork(num_class)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 27\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, weight_decay\u001b[39m=\u001b[39m\u001b[39m5e-3\u001b[39m)\n\u001b[1;32m     28\u001b[0m scaler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mGradScaler()\n\u001b[1;32m     29\u001b[0m loss_hist \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "output_names = ['AR', 'ECG']\n",
    "for uid in train_dataset.data.keys():\n",
    "    train_idx = [idx[0] for idx in train_dataset.idxs if idx[1] != uid]\n",
    "    val_idx = [idx[0] for idx in train_dataset.idxs if idx[1] == uid]\n",
    "\n",
    "    actual_train = random.sample(train_idx, len(train_idx) // 5)\n",
    "    print('Training UID {} with {} samples'.format(uid, len(actual_train)))\n",
    "\n",
    "    train_set = data.Subset(train_dataset, actual_train)\n",
    "    val_set = data.Subset(val_dataset, val_idx)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=series_collate,\n",
    "        **loader_kwargs\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=series_collate,\n",
    "        **loader_kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "    # training\n",
    "    lr = learning_rate\n",
    "    model = MainNetwork(num_class).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-3)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    loss_hist = []\n",
    "    \n",
    "    iter_idx = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        if (epoch % 5 == 0) and (epoch != 0):\n",
    "            lr *= 0.1\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "        num_iter = len(train_loader)\n",
    "        for batch_idx, (inputs, labels1, labels2, _) in enumerate(train_loader):\n",
    "            iter_idx = (epoch * num_iter) + batch_idx\n",
    "            inputs, labels1, labels2 = inputs.cuda(), labels1.cuda(), labels2.cuda()\n",
    "            losses = []\n",
    "            optimizer.zero_grad()\n",
    "            with torch.autocast(device.type):\n",
    "                outputs = model(inputs)\n",
    "                labels = [labels1, labels2]\n",
    "                for i in range(len(labels)):\n",
    "                    if output_names[i] == 'ECG':\n",
    "                        mae, mse, rmse, pcc, ccc = eval_metrics(outputs[i].permute(0, 2, 1).reshape((batch_size * 2560, 2)), labels[i].permute(0, 2, 1).reshape((batch_size * 2560, 2)))\n",
    "                    else:\n",
    "                        mae, mse, rmse, pcc, ccc = eval_metrics(outputs[i], labels[i])\n",
    "                    loss = (1-ccc).mean() + alpha * rmse\n",
    "                    losses.append(loss)\n",
    "\n",
    "                    logging('Train', output_names[i], log_writer, loss, mae, mse, rmse, pcc, ccc, iter_idx)\n",
    "                    print('\\n Epoch [{}/{}] Iter[{}/{}] Mode: {} \\t loss: {:.2f} \\t MAE: {:.2f} \\t MSE: {:.2f} \\t RMSE: {:.2f} \\t PCC:{} \\t CCC:{} '.format(\n",
    "                        epoch,\n",
    "                        epochs,\n",
    "                        batch_idx + 1,\n",
    "                        num_iter,\n",
    "                        output_names[i],\n",
    "                        loss.item(),\n",
    "                        mae.item(),\n",
    "                        mse.item(),\n",
    "                        rmse.item(),\n",
    "                        ['%.2f' % elem for elem in pcc.tolist()],\n",
    "                        ['%.2f' % elem for elem in ccc.tolist()],\n",
    "                    ))\n",
    "\n",
    "            loss = beta * losses[0] + gamma * losses[1]\n",
    "            log_writer.add_scalar('TotalLoss/{}'.format('Train'), loss, iter_idx)\n",
    "            print('\\n Epoch [{}/{}] Iter[{}/{}]\\t TotalLoss: {:.2f}'.format(\n",
    "                epoch,\n",
    "                epochs,\n",
    "                batch_idx + 1,\n",
    "                num_iter,\n",
    "                loss.item()\n",
    "            ))\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # release GPU memory\n",
    "            del inputs, labels, labels1, labels2, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # validation\n",
    "        y_pred_AR, y_true_AR, y_pred_ECG, y_true_ECG = run_val(model, test_loader, batch_size)\n",
    "        losses = val_log(log_writer, alpha, y_pred_AR, y_true_AR, y_pred_ECG, y_true_ECG, epoch)\n",
    "        loss = beta * losses[0] + gamma * losses[1]\n",
    "        log_writer.add_scalar('TotalLoss/{}'.format('Validation'), loss, epoch)\n",
    "        print('\\n Epoch [{}/{}] \\t TotalLoss: {:.2f}'.format(\n",
    "            epoch,\n",
    "            epochs,\n",
    "            loss.item()\n",
    "        ))\n",
    "        log_writer.flush()\n",
    "        print('\\n')\n",
    "        del losses, y_pred_AR, y_true_AR, y_pred_ECG, y_true_ECG\n",
    "        torch.cuda.empty_cache()\n",
    "        loss_hist.append(loss)\n",
    "        if loss_hist[-1] == min(loss_hist):\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model': model.state_dict(),\n",
    "            },\n",
    "                os.path.join(savemodel, 'pid_{}.pth.tar'.format(uid))\n",
    "            )\n",
    "        log_writer.flush()\n",
    "        \n",
    "del model\n",
    "log_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer\u001b[39m.\u001b[39;49mparam_groups[\u001b[39m'\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "optimizer.param_groups[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['lr'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMIGO 37: Test samples: 68\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "log_writer = SummaryWriter(os.path.join(*[log_dir, 'AMIGOS', 'Test', datetime.now().strftime('%b%d_%H-%M-%S_eval')]))\n",
    "\n",
    "model_lst = os.listdir(savemodel)\n",
    "model_lst = [os.path.join(savemodel, fname) for fname in model_lst]\n",
    "\n",
    "y_pred_ARs = []\n",
    "y_true_ARs = []\n",
    "y_pred_ECGs = []\n",
    "y_true_ECGs = []\n",
    "for model_path in model_lst:\n",
    "    test_loader = eval_dataloader(model_path, val_dataset, batch_size, loader_kwargs)\n",
    "    \n",
    "    print('AMIGO {}: Test samples: {}'.format(uid, len(test_loader)))\n",
    "    if len(test_loader) == 0:\n",
    "        continue\n",
    "    state_dicts = torch.load(model_path)\n",
    "    model.load_state_dict(state_dicts['model'])\n",
    "\n",
    "    y_pred_AR, y_true_AR, y_pred_ECG, y_true_ECG = run_val(model, test_loader, batch_size)\n",
    "    y_pred_ARs.append(y_pred_AR.cpu())\n",
    "    y_true_ARs.append(y_true_AR.cpu())\n",
    "    y_pred_ECGs.append(y_pred_ECG.cpu())\n",
    "    y_true_ECGs.append(y_true_ECG.cpu())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "del model\n",
    "\n",
    "y_pred_ARs = torch.cat(y_pred_ARs)\n",
    "y_true_ARs = torch.cat(y_true_ARs)\n",
    "y_pred_ECGs = torch.cat(y_pred_ECGs)\n",
    "y_true_ECGs = torch.cat(y_true_ECGs)\n",
    "val_log(log_writer, alpha, y_pred_ARs, y_true_ARs, y_pred_ECGs, y_true_ECGs)\n",
    "\n",
    "log_writer.flush()\n",
    "log_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
