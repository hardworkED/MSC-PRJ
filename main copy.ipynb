{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from data.datasets import AMIGOS, series_collate\n",
    "from architecture.MainNetwork import MainNetwork\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = False\n",
    "loader_kwargs = {'num_workers': 4, 'pin_memory': True, 'shuffle': True, 'drop_last': True}\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.current_device()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "savemodel = '/scratch/ec22150/rmse/models/'\n",
    "if not os.path.exists(savemodel):\n",
    "    os.makedirs(savemodel)\n",
    "root_path = 'data/face_segments'\n",
    "labels_path = 'data/Data_Preprocessed_segmented.json'\n",
    "vids_dir = 'data/vids_segments'\n",
    "remove_mov = 'data/ignore_mov.json'\n",
    "num_class = 4096\n",
    "batch_size = 4\n",
    "learning_rate = 1e-05\n",
    "epochs = 20\n",
    "alpha = 2\n",
    "beta = 1\n",
    "scale_factor = 1\n",
    "gamma = scale_factor\n",
    "downsample = 8\n",
    "normalize_val = {\n",
    "    'AR': {'min': -0.42818420244970845, 'range': 0.40530026133943436 - -0.42818420244970845},\n",
    "    'ECG': {'min': -2281.0594032292756, 'range': 2340.911172156569 - -2281.0594032292756},\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '/scratch/ec22150/rmse/log'\n",
    "log_writer = SummaryWriter(os.path.join(*[log_dir, 'AMIGOS', 'Train', datetime.now().strftime('%b%d_%H-%M-%S')]))\n",
    "\n",
    "x_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize([0.4168, 0.3074, 0.2607], [0.2426, 0.1997, 0.1870])\n",
    "])\n",
    "\n",
    "y_transform = transforms.Compose([\n",
    "    torch.FloatTensor\n",
    "])\n",
    "\n",
    "train_dataset = AMIGOS(\n",
    "    root_path=root_path,\n",
    "    labels_path=labels_path,\n",
    "    vids_dir=vids_dir,\n",
    "    remove_mov=remove_mov,\n",
    "    x_transform=x_transform,\n",
    "    y_transform=y_transform,\n",
    "    downsample=downsample,\n",
    "    normalize_val=normalize_val\n",
    ")\n",
    "\n",
    "x_transform = transforms.Compose([\n",
    "    transforms.Normalize([0.4168, 0.3074, 0.2607], [0.2426, 0.1997, 0.1870])\n",
    "])\n",
    "\n",
    "val_dataset = AMIGOS(\n",
    "    root_path=root_path,\n",
    "    labels_path=labels_path,\n",
    "    vids_dir=vids_dir,\n",
    "    remove_mov=remove_mov,\n",
    "    x_transform=x_transform,\n",
    "    y_transform=y_transform,\n",
    "    downsample=downsample,\n",
    "    normalize_val=normalize_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     optimizer\u001b[39m.\u001b[39mparam_groups[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m lr\n\u001b[1;32m     41\u001b[0m num_iter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[0;32m---> 42\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (inputs, labels1, labels2, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[1;32m     43\u001b[0m     iter_idx \u001b[39m=\u001b[39m (epoch \u001b[39m*\u001b[39m num_iter) \u001b[39m+\u001b[39m batch_idx\n\u001b[1;32m     44\u001b[0m     inputs, labels1, labels2 \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mcuda(), labels1\u001b[39m.\u001b[39mcuda(), labels2\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/MSCPRJ/MSC-PRJ/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/MSCPRJ/MSC-PRJ/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/MSCPRJ/MSC-PRJ/venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/context.py:277\u001b[0m, in \u001b[0;36mForkProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    276\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_fork\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/popen_fork.py:66\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m parent_r, child_w \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpipe()\n\u001b[1;32m     65\u001b[0m child_r, parent_w \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpipe()\n\u001b[0;32m---> 66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mfork()\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     68\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "output_names = ['AR', 'ECG']\n",
    "for uid in train_dataset.data.keys():\n",
    "    if uid in [11, 29, 34, 37, 9, 35, 5, 12, 40, 30, 26, 17, 6, 25, 15, 4, 38, 22, 14, 27, 13, 23, 21, 36, 2, 20]:\n",
    "        continue\n",
    "    train_idx = [idx[0] for idx in train_dataset.idxs if idx[1] != uid]\n",
    "    val_idx = [idx[0] for idx in train_dataset.idxs if idx[1] == uid]\n",
    "\n",
    "    actual_train = random.sample(train_idx, len(train_idx) // 5)\n",
    "    print('Training UID {} with {} samples'.format(uid, len(actual_train)))\n",
    "\n",
    "    train_set = data.Subset(train_dataset, actual_train)\n",
    "    val_set = data.Subset(val_dataset, val_idx)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=series_collate,\n",
    "        **loader_kwargs\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=series_collate,\n",
    "        **loader_kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "    # training\n",
    "    lr = learning_rate\n",
    "    model = MainNetwork(num_class).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-3)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    loss_hist = []\n",
    "    \n",
    "    iter_idx = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        if (epoch % 5 == 0) and (epoch != 0):\n",
    "            lr *= 0.1\n",
    "            optimizer.param_groups[0]['lr'] = lr\n",
    "        num_iter = len(train_loader)\n",
    "        for batch_idx, (inputs, labels1, labels2, _) in enumerate(train_loader):\n",
    "            iter_idx = (epoch * num_iter) + batch_idx\n",
    "            inputs, labels1, labels2 = inputs.cuda(), labels1.cuda(), labels2.cuda()\n",
    "            losses = []\n",
    "            optimizer.zero_grad()\n",
    "            with torch.autocast(device.type):\n",
    "                outputs = model(inputs)\n",
    "                labels = [labels1, labels2]\n",
    "                for i in range(len(labels)):\n",
    "                    if output_names[i] == 'ECG':\n",
    "                        mae, mse, rmse, pcc, ccc = eval_metrics(outputs[i].permute(0, 2, 1).reshape((batch_size * 2560, 2)), labels[i].permute(0, 2, 1).reshape((batch_size * 2560, 2)))\n",
    "                    else:\n",
    "                        mae, mse, rmse, pcc, ccc = eval_metrics(outputs[i], labels[i])\n",
    "                    loss = rmse\n",
    "                    losses.append(loss)\n",
    "\n",
    "                    logging('Train-{}'.format(uid), output_names[i], log_writer, loss, mae, mse, rmse, pcc, ccc, iter_idx)\n",
    "                    print('\\n Epoch [{}/{}] Iter[{}/{}] Mode: {} \\t loss: {:.2f} \\t MAE: {:.2f} \\t MSE: {:.2f} \\t RMSE: {:.2f} \\t PCC:{} \\t CCC:{} '.format(\n",
    "                        epoch,\n",
    "                        epochs,\n",
    "                        batch_idx + 1,\n",
    "                        num_iter,\n",
    "                        output_names[i],\n",
    "                        loss.item(),\n",
    "                        mae.item(),\n",
    "                        mse.item(),\n",
    "                        rmse.item(),\n",
    "                        ['%.2f' % elem for elem in pcc.tolist()],\n",
    "                        ['%.2f' % elem for elem in ccc.tolist()],\n",
    "                    ))\n",
    "\n",
    "            loss = beta * losses[0] + gamma * losses[1]\n",
    "            log_writer.add_scalar('TotalLoss/{}-{}'.format('Train', uid), loss, iter_idx)\n",
    "            print('\\n Epoch [{}/{}] Iter[{}/{}]\\t TotalLoss: {:.2f}'.format(\n",
    "                epoch,\n",
    "                epochs,\n",
    "                batch_idx + 1,\n",
    "                num_iter,\n",
    "                loss.item()\n",
    "            ))\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # release GPU memory\n",
    "            # del inputs, labels, labels1, labels2, outputs\n",
    "            # torch.cuda.empty_cache()\n",
    "        \n",
    "        # validation\n",
    "        y_pred_AR, y_true_AR, y_pred_ECG, y_true_ECG = run_val(model, test_loader, batch_size)\n",
    "        losses = val_log(log_writer, alpha, scale_factor, y_pred_AR, y_true_AR, y_pred_ECG, y_true_ECG, epoch, uid=uid)\n",
    "        loss = beta * losses[0] + gamma * losses[1]\n",
    "        log_writer.add_scalar('TotalLoss/{}-{}'.format('Validation', uid), loss, epoch)\n",
    "        print('\\n Epoch [{}/{}] \\t TotalLoss: {:.2f}'.format(\n",
    "            epoch,\n",
    "            epochs,\n",
    "            loss.item()\n",
    "        ))\n",
    "        log_writer.flush()\n",
    "        print('\\n')\n",
    "        # del losses, y_pred_AR, y_true_AR, y_pred_ECG, y_true_ECG\n",
    "        # torch.cuda.empty_cache()\n",
    "        loss_hist.append(loss)\n",
    "        if loss_hist[-1] == min(loss_hist):\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model': model.state_dict(),\n",
    "            },\n",
    "                os.path.join(savemodel, 'pid_{}.pth.tar'.format(uid))\n",
    "            )\n",
    "        log_writer.flush()\n",
    "    clear_output()\n",
    "        \n",
    "del model\n",
    "log_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMIGO 37: Test samples: 85\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "log_writer = SummaryWriter(os.path.join(*[log_dir, 'AMIGOS', 'Test', datetime.now().strftime('%b%d_%H-%M-%S_eval')]))\n",
    "\n",
    "model_lst = os.listdir(savemodel)\n",
    "model_lst = [os.path.join(savemodel, fname) for fname in model_lst]\n",
    "model = MainNetwork(num_class).to(device)\n",
    "\n",
    "y_pred_ARs = []\n",
    "y_true_ARs = []\n",
    "y_pred_ECGs = []\n",
    "y_true_ECGs = []\n",
    "for model_path in model_lst:\n",
    "    test_loader = eval_dataloader(model_path, val_dataset, batch_size, loader_kwargs, uid=37)\n",
    "    \n",
    "    if len(test_loader) == 0:\n",
    "        continue\n",
    "    state_dicts = torch.load(model_path)\n",
    "    model.load_state_dict(state_dicts['model'])\n",
    "\n",
    "    y_pred_AR, y_true_AR, y_pred_ECG, y_true_ECG = run_val(model, test_loader, batch_size)\n",
    "    y_pred_ARs.append(y_pred_AR.cpu())\n",
    "    y_true_ARs.append(y_true_AR.cpu())\n",
    "    y_pred_ECGs.append(y_pred_ECG.cpu())\n",
    "    y_true_ECGs.append(y_true_ECG.cpu())\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# del model\n",
    "\n",
    "# y_pred_ARs = torch.cat(y_pred_ARs)\n",
    "# y_true_ARs = torch.cat(y_true_ARs)\n",
    "# y_pred_ECGs = torch.cat(y_pred_ECGs)\n",
    "# y_true_ECGs = torch.cat(y_true_ECGs)\n",
    "# val_log(log_writer, alpha, scale_factor, y_pred_ARs, y_true_ARs, y_pred_ECGs, y_true_ECGs)\n",
    "\n",
    "# log_writer.flush()\n",
    "# log_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR-min:-0.42818420244970845\tAR-max:0.40530026133943436\tECG-min:-2281.0594032292756\tECG-max:2340.911172156569\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "AR = [x[0] for x in val_dataset.labels]\n",
    "ECG = [x[1] for x in val_dataset.labels]\n",
    "AR = np.array(AR).ravel()\n",
    "ECG = np.array(ECG).ravel()\n",
    "print('AR-min:{}\\tAR-max:{}\\tECG-min:{}\\tECG-max:{}'.format(AR.min(), AR.max(), ECG.min(), ECG.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1125, -0.1279, -0.0298,  ..., -0.1556,  0.1115, -0.1545],\n",
       "         [-0.0381, -0.1077,  0.0009,  ..., -0.0934, -0.0747,  0.0953]],\n",
       "\n",
       "        [[-0.0829, -0.1417, -0.0419,  ..., -0.1501,  0.0850, -0.1196],\n",
       "         [-0.0145, -0.0513,  0.0121,  ..., -0.0623, -0.0785,  0.0334]],\n",
       "\n",
       "        [[-0.0684, -0.1164, -0.0248,  ..., -0.1279,  0.0399, -0.0859],\n",
       "         [ 0.0229, -0.0487,  0.0524,  ..., -0.0443, -0.0660,  0.0345]],\n",
       "\n",
       "        [[-0.0796, -0.1238, -0.0317,  ..., -0.1335,  0.0815, -0.1087],\n",
       "         [ 0.0019, -0.0670,  0.0169,  ..., -0.0695, -0.0766,  0.0553]]],\n",
       "       device='cuda:1', dtype=torch.float16, grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0215, -2.0254, -2.0059,  ..., -2.0312, -1.9785, -2.0312],\n",
       "         [-2.0078, -2.0215, -2.0000,  ..., -2.0195, -2.0156, -1.9814]],\n",
       "\n",
       "        [[-2.0176, -2.0273, -2.0078,  ..., -2.0293, -1.9824, -2.0234],\n",
       "         [-2.0039, -2.0117, -1.9971,  ..., -2.0117, -2.0156, -1.9941]],\n",
       "\n",
       "        [[-2.0137, -2.0234, -2.0039,  ..., -2.0254, -1.9922, -2.0176],\n",
       "         [-1.9951, -2.0098, -1.9893,  ..., -2.0098, -2.0117, -1.9941]],\n",
       "\n",
       "        [[-2.0156, -2.0254, -2.0059,  ..., -2.0273, -1.9844, -2.0215],\n",
       "         [-2.0000, -2.0137, -1.9971,  ..., -2.0137, -2.0156, -1.9893]]],\n",
       "       device='cuda:1', dtype=torch.float16, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(outputs[1] - 10)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
